{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda9d65e615e5564808b0fd10cb7293bc83",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Get the randow number, '-0.5' means get negative numbers\n",
    "np.random.rand(3,3) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# for sigmoid function expit()\n",
    "import scipy.special\n",
    "\n",
    "# neuralNetwork class definition\n",
    "class neuralNetwork:\n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrates):\n",
    "\n",
    "        # set number of nodes in each input, hidden and output layers\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # link weight matrices, Wih and Who\n",
    "        # weight inside the arrays are w_i_j, where link from nodes i to nodes j\n",
    "    \n",
    "        # the easy way\n",
    "        # self.wih = (np.random.rand(self.hnodes, self.inodes) - 0.5)\n",
    "        # self.who = (np.random.rand(self.onodes, self.hnodes) - 0.5)\n",
    "\n",
    "        # \n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5)\\\n",
    "                                ,(self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5)\\\n",
    "                                ,(self.onodes, self.hnodes))\n",
    "        # learning rate\n",
    "        self.lr = learningrates\n",
    "        pass\n",
    "\n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert list to 2d array \n",
    "        inputs = np.array(inputs_list, ndmin = 2).T\n",
    "        targets = np.array(targets_list, ndmin = 2).T\n",
    "\n",
    "        # calculate the signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_output = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # calculate the signals into final output layer\n",
    "        final_input = np.dot(self.who, hidden_output)\n",
    "\n",
    "        # calculate the signals emerging from final out layer\n",
    "        final_output = self.activation_function(final_input)        \n",
    "\n",
    "        # Core of neural network\n",
    "        # error = (target - output)\n",
    "        output_error = targets_list - final_output\n",
    "\n",
    "        # hidden layer error is the outputs error, split by weights, recombined at hidden layer\n",
    "        hidden_error = np.dot(self.who.T, output_error)\n",
    "\n",
    "        # update the weights for link between the hidden layers and ouput layers\n",
    "        self.who += self.lr * np.dot((output_error * final_output *\\\n",
    "                            (1 - final_output)), np.transpose(hidden_output))\n",
    "        # update the weights for link between the input layers and hidden layers\n",
    "        self.wih += self.lr * np.dot((hidden_error * hidden_output *\\\n",
    "                            (1 - hidden_output)), np.transpose(hidden_output))\n",
    "        pass\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin= 2).T\n",
    "\n",
    "        # calculate the signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_output = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # calculate the signals into final output layer\n",
    "        final_input = np.dot(self.who, hidden_output)\n",
    "        \n",
    "        # calculate the signals emerging from final out layer\n",
    "        final_output = self.activation_function(final_input)\n",
    "        return final_output\n",
    "    \n",
    "n = neuralNetwork(3,3,3,0)\n",
    "n.query([1.0, 0.5, -1.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of input, hidden and output nodes\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "# learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of neural networl\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "datefile = open(r'D:\\GitHub\\Neural-Network\\mnist_dateset\\mnist_train_100.csv', 'r')\n",
    "datelist = datefile.readlines()\n",
    "datefile.close()\n",
    "len(datelist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}